# -*- coding: utf-8 -*-
"""quiz1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pa4LShPlg3GiR4DNCRENLI_la0DTUdJ7

**Matric no : 1824208**

Part A and B
"""

# Commented out IPython magic to ensure Python compatibility.
from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode
from IPython.display import Image
import cv2
import numpy as np
import matplotlib.pyplot as plt 
from PIL import Image 
# %matplotlib inline

#capturing 1st image
def take_photo(filename='photo1.jpg', quality=0.8):
  js = Javascript('''
    async function takePhoto(quality) {
      const div = document.createElement('div');
      const capture = document.createElement('button');
      capture.textContent = 'Capture';
      div.appendChild(capture);

      const video = document.createElement('video');
      video.style.display = 'block';
      const stream = await navigator.mediaDevices.getUserMedia({video: true});

      document.body.appendChild(div);
      div.appendChild(video);
      video.srcObject = stream;
      await video.play();

      // Resize the output to fit the video element.
      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

      // Wait for Capture to be clicked.
      await new Promise((resolve) => capture.onclick = resolve);

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      stream.getVideoTracks()[0].stop();
      div.remove();
      return canvas.toDataURL('image/jpeg', quality);
    }
    ''')
  display(js)
  data = eval_js('takePhoto({})'.format(quality))
  binary = b64decode(data.split(',')[1])
  with open(filename, 'wb') as f:
    f.write(binary)
  return filename

try:
  filename = take_photo()
  print('Saved to {}'.format(filename))
  
  # Show the image which was just taken.
  display(Image(filename))
except Exception as err:
  # Errors will be thrown if the user does not have a webcam or if they do not
  # grant the page permission to access it.
  print(str(err))

#capturing 2nd image
def take_photo(filename='photo2.jpg', quality=0.8):
  js = Javascript('''
    async function takePhoto(quality) {
      const div = document.createElement('div');
      const capture = document.createElement('button');
      capture.textContent = 'Capture';
      div.appendChild(capture);

      const video = document.createElement('video');
      video.style.display = 'block';
      const stream = await navigator.mediaDevices.getUserMedia({video: true});

      document.body.appendChild(div);
      div.appendChild(video);
      video.srcObject = stream;
      await video.play();

      // Resize the output to fit the video element.
      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

      // Wait for Capture to be clicked.
      await new Promise((resolve) => capture.onclick = resolve);

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      stream.getVideoTracks()[0].stop();
      div.remove();
      return canvas.toDataURL('image/jpeg', quality);
    }
    ''')
  display(js)
  data = eval_js('takePhoto({})'.format(quality))
  binary = b64decode(data.split(',')[1])
  with open(filename, 'wb') as f:
    f.write(binary)
  return filename

try:
  filename = take_photo()
  print('Saved to {}'.format(filename))
  
  # Show the image which was just taken.
  display(Image(filename))
except Exception as err:
  print(str(err))

#capturing 3rd image
def take_photo(filename='photo3.jpg', quality=0.8):
  js = Javascript('''
    async function takePhoto(quality) {
      const div = document.createElement('div');
      const capture = document.createElement('button');
      capture.textContent = 'Capture';
      div.appendChild(capture);

      const video = document.createElement('video');
      video.style.display = 'block';
      const stream = await navigator.mediaDevices.getUserMedia({video: true});

      document.body.appendChild(div);
      div.appendChild(video);
      video.srcObject = stream;
      await video.play();

      // Resize the output to fit the video element.
      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

      // Wait for Capture to be clicked.
      await new Promise((resolve) => capture.onclick = resolve);

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      stream.getVideoTracks()[0].stop();
      div.remove();
      return canvas.toDataURL('image/jpeg', quality);
    }
    ''')
  display(js)
  data = eval_js('takePhoto({})'.format(quality))
  binary = b64decode(data.split(',')[1])
  with open(filename, 'wb') as f:
    f.write(binary)
  return filename

try:
  filename = take_photo()
  print('Saved to {}'.format(filename))
  
  # Show the image which was just taken.
  display(Image(filename))
except Exception as err:
  print(str(err))

#A path is created to read image files
path = "/contentgdrive/MyDrive/images/"

# Open image using openCV2
img1 = cv2.imread("photo1.jpg")
img2 = cv2.imread("photo2.jpg")
img3 = cv2.imread("photo3.jpg")

  
# Notice the COLOR_BGR2RGB which means that the color is
# # converted from BGR to RGB
# color_coverted = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

color_converted1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB) 
color_converted2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)  
color_converted3 = cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)
  
# using pillow
# pil_image = Image.fromarray(color_coverted)
# pil_image.show()

# using matplotlib
# plt.figure(figsize=(10,10))
plt.imshow(color_converted1)
plt.show()
plt.imshow(color_converted2)
plt.show()
plt.imshow(color_converted3)
plt.show()

#A function displayImage is created to ease processes 
def displayImage(image): 
    if len(image.shape)==3:
        color_converted = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        plt.imshow(color_converted)
        plt.show()
        
    else:
        plt.imshow(image, cmap="gray")
        plt.show()

kernel = np.ones((3,3), np.float32)/9
#Images are converted to grayscale
grayImage1 = cv2.cvtColor(img1,cv2.COLOR_RGB2GRAY)
grayImage2 = cv2.cvtColor(img2,cv2.COLOR_RGB2GRAY)
grayImage3 = cv2.cvtColor(img3,cv2.COLOR_RGB2GRAY)

convolvedImg1 = cv2.filter2D(grayImage1, -1,kernel)
convolvedImg2 = cv2.filter2D(grayImage2, -1,kernel)
convolvedImg3 = cv2.filter2D(grayImage3, -1,kernel)

#Grayscaled images are displayed
displayImage(convolvedImg1)
displayImage(convolvedImg2)
displayImage(convolvedImg3)

#GaussianBlur is applied to blur the images
imgBlur1 = cv2.GaussianBlur(grayImage1,(45,45),0)
imgBlur2 = cv2.GaussianBlur(grayImage2,(45,45),0)
imgBlur3 = cv2.GaussianBlur(grayImage3,(45,45),0)

displayImage(imgBlur1)
displayImage(imgBlur2)
displayImage(imgBlur3)

#Canny Edge Detection is applied
imgCanny1 = cv2.Canny(imgBlur1,20,70)
imgCanny2 = cv2.Canny(imgBlur2,20,70)
imgCanny3 = cv2.Canny(imgBlur3,20,70)


displayImage(imgCanny1)
displayImage(imgCanny2)
displayImage(imgCanny3)

#Sobel Edge Detection is applied
sobelx1 = cv2.Sobel(imgBlur1, cv2.CV_8U,1,0,ksize=3)
sobelx2 = cv2.Sobel(imgBlur2, cv2.CV_8U,1,0,ksize=3)
sobelx3 = cv2.Sobel(imgBlur3, cv2.CV_8U,1,0,ksize=3)

sobely1 = cv2.Sobel(imgBlur1, cv2.CV_8U,0,1,ksize=3)
sobely2 = cv2.Sobel(imgBlur2, cv2.CV_8U,0,1,ksize=3)
sobely3 = cv2.Sobel(imgBlur3, cv2.CV_8U,0,1,ksize=3)

imgSobel1 = sobelx1 + sobely1
displayImage(imgSobel1)

imgSobel2 = sobelx2 + sobely2
displayImage(imgSobel2)

imgSobel3 = sobelx3 + sobely3
displayImage(imgSobel3)

"""Part C"""

from google.colab import drive
drive.mount('/content/gdrive')

path = "/content/gdrive/MyDrive/mv/"

image = cv2.imread(path+"coins.jfif")
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
plt.imshow(gray, cmap='gray');

# Apply GaussianBlur
blur = cv2.GaussianBlur(gray, (11,11), 0)
plt.imshow(blur, cmap='gray')

#canny edge
canny = cv2.Canny(blur, 30, 150, 3)
plt.imshow(canny, cmap='gray')

#remove the noise
dilated = cv2.dilate(canny, (1,1), iterations = 2)
plt.imshow(dilated, cmap='gray')

#draw Contours to the coins
(cnt, heirarchy) = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
cv2.drawContours(rgb, cnt, -1, (0,255,0), 2)

plt.imshow(rgb)

print('Coins in the image: ', len(cnt))
plt.show()